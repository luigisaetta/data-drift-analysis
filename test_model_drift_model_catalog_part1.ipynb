{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0091373a",
   "metadata": {},
   "source": [
    "### Model Drift Analysis: train the model and save to Model Catalog\n",
    "\n",
    "Model Drift Analysis require two dataset containing not only the features (xi) but also the target.\n",
    "\n",
    "It means that, in order to monitor Model's performances and detect Model drift, we need, in some way, to collect data and analyze the results in order to define the \"ground truth\".\n",
    "\n",
    "In this NB I have put a prototype that can be used to **start working on Model Drift**.\n",
    "\n",
    "The dataset used is again the Employee Attrition Data and the model is based on LightGBM (GBM) and Sklearn pipeline.\n",
    "\n",
    "We simulate a Data Drift (adding a \"shift\" to some features) in order to make performances worse.\n",
    "\n",
    "In the First Part of the NB we train a model on a reference dataset and we save the pipeline + the metrics computed on a reference validation dataset.\n",
    "In the second part we reload the model (pipeline) and we re-evaluate the metrics on a new dataset.\n",
    "All the  results are saved in a csv file that can be easily loaded in a DB."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a405cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import ads\n",
    "from ads import set_auth\n",
    "\n",
    "# to save to Model Catalog\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_metadata import UseCaseType, MetadataCustomCategory\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "\n",
    "# used to serialize the pipeline\n",
    "from pickle import dump, load\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import get_scorer, make_scorer, f1_score, roc_auc_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# added to handle with pipelines\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2185d94c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.10\n"
     ]
    }
   ],
   "source": [
    "# we need ads 2.5.10 or greater\n",
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e780da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:~/.oci/config file not exists, default value oci.config.DEFAULT_LOCATION used instead\n"
     ]
    }
   ],
   "source": [
    "# set RP\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec99bedc",
   "metadata": {},
   "source": [
    "### First Part: train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a880a61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# definisco le funzioni che identificano le categorie di colonne\n",
    "#\n",
    "def cat_cols_selector(df, target_name):\n",
    "    # the input is the dataframe\n",
    "    \n",
    "    # cols with less than THR values are considered categoricals\n",
    "    THR = 10\n",
    "    \n",
    "    nunique = df.nunique()\n",
    "    types = df.dtypes\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if ((types[col] == 'object') or (nunique[col] < THR)):\n",
    "            # print(col)\n",
    "            if col != target_name:\n",
    "                col_list.append(col)\n",
    "    \n",
    "    return col_list\n",
    "\n",
    "def num_cols_selector(df, target_name):\n",
    "    THR = 10\n",
    "    \n",
    "    types = df.dtypes\n",
    "    nunique = df.nunique()\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if (types[col] != 'object') and (nunique[col] >= THR): \n",
    "            # print(col)\n",
    "            if col != target_name:\n",
    "                col_list.append(col)\n",
    "    \n",
    "    return col_list\n",
    "\n",
    "def load_as_dataframe(path):\n",
    "    ds = DatasetFactory.open(path,\n",
    "                             target=\"Attrition\").set_positive_class('Yes')\n",
    "\n",
    "    ds_up = ds.up_sample()\n",
    "\n",
    "    # drop unneeded columns\n",
    "    cols_to_drop = ['Directs','name', 'Over18','WeeklyWorkedHours','EmployeeNumber']\n",
    "\n",
    "    ds_used = ds_up.drop(columns=cols_to_drop)\n",
    "    \n",
    "    df_used = ds_used.to_pandas_dataframe()\n",
    "    \n",
    "    \n",
    "\n",
    "    # train, test split (lo faccio direttamente sui dataframe)\n",
    "    df_train, df_test = train_test_split(df_used, shuffle=True, test_size=0.2, random_state = 1234)\n",
    "\n",
    "    print(\"# of samples in train set\", df_train.shape[0])\n",
    "    print(\"# of samples in test set\", df_test.shape[0])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9041e15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5edd8806fd3e4a619f8ca6682a1ee422",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in train set 1972\n",
      "# of samples in test set 494\n",
      "\n",
      "Numerical columns: ['Age', 'SalaryLevel', 'CommuteLength', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'YearsinIndustry', 'YearsOnJob', 'YearsAtCurrentLevel', 'YearsSinceLastPromotion', 'YearsWithCurrManager'] (13)\n",
      "\n",
      "Categorical columns: ['TravelForWork', 'JobFunction', 'EducationalLevel', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TrainingTimesLastYear', 'WorkLifeBalance'] (17)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and do upsampling\n",
    "TARGET = 'Attrition'\n",
    "\n",
    "attrition_path = \"/opt/notebooks/ads-examples/oracle_data/orcl_attrition.csv\"\n",
    "\n",
    "df_train, df_test = load_as_dataframe(attrition_path)\n",
    "\n",
    "# uso ancora la classe dataset per fare l'upsampling\n",
    "\n",
    "cat_cols = cat_cols_selector(df_train, TARGET)\n",
    "num_cols = num_cols_selector(df_train, TARGET)\n",
    "\n",
    "print()\n",
    "print(f'Numerical columns: {num_cols} ({len(num_cols)})')\n",
    "print()\n",
    "print(f'Categorical columns: {cat_cols} ({len(cat_cols)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f15dd66",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# creo la parte Transformers per le pipeline\n",
    "#\n",
    "\n",
    "# per questo dataset non vi sono missing values\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('standard_scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64331f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop([TARGET], axis=1), df_train[TARGET]\n",
    "X_test, y_test = df_test.drop([TARGET], axis=1), df_test[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2cc23ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# definisco la pipeline completa\n",
    "#\n",
    "clf = Pipeline(steps=[('preprocessor', transformations),\n",
    "                           ('clf', lgb.LGBMClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b8d1520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('standard_scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Age', 'SalaryLevel',\n",
       "                                                   'CommuteLength',\n",
       "                                                   'HourlyRate',\n",
       "                                                   'MonthlyIncome',\n",
       "                                                   'MonthlyRate',\n",
       "                                                   'NumCompaniesWorked',\n",
       "                                                   'PercentSalaryHike',\n",
       "                                                   'YearsinIndustry',\n",
       "                                                   'YearsOnJob',\n",
       "                                                   'YearsAtCurrentLevel',\n",
       "                                                   'YearsSinceLastPromoti...\n",
       "                                                                   OrdinalEncoder(handle_unknown='use_encoded_value',\n",
       "                                                                                  unknown_value=-1))]),\n",
       "                                                  ['TravelForWork',\n",
       "                                                   'JobFunction',\n",
       "                                                   'EducationalLevel',\n",
       "                                                   'EducationField',\n",
       "                                                   'EnvironmentSatisfaction',\n",
       "                                                   'Gender', 'JobInvolvement',\n",
       "                                                   'JobLevel', 'JobRole',\n",
       "                                                   'JobSatisfaction',\n",
       "                                                   'MaritalStatus', 'OverTime',\n",
       "                                                   'PerformanceRating',\n",
       "                                                   'RelationshipSatisfaction',\n",
       "                                                   'StockOptionLevel',\n",
       "                                                   'TrainingTimesLastYear',\n",
       "                                                   'WorkLifeBalance'])])),\n",
       "                ('clf', LGBMClassifier())])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19665d50",
   "metadata": {},
   "source": [
    "### Score the Model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5ab7bc54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set result:\n",
      "{'accuracy': 0.9494, 'roc_auc': 0.9951}\n"
     ]
    }
   ],
   "source": [
    "test_pred = clf.predict(X_test)\n",
    "test_probas = clf.predict_proba(X_test)\n",
    "\n",
    "print('Validation set result:')\n",
    "\n",
    "roc_auc = round(roc_auc_score(y_test, test_probas[:,1]), 4)\n",
    "acc = round(accuracy_score(y_test, test_pred), 4)\n",
    "\n",
    "# this is the Object that will be saved in the Catalog\n",
    "metrics = {\n",
    "    \"accuracy\" : acc,\n",
    "    \"roc_auc\" : roc_auc\n",
    "}\n",
    "\n",
    "print(str(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e246e3e",
   "metadata": {},
   "source": [
    "#### Save metrics and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b02dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in a file the metrics computed on the reference set\n",
    "now = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "dict_ref = [{\n",
    "    \"ts_date\": now,\n",
    "    \"model_name\": \"lgb1\",\n",
    "    \"algorithm\": \"lightgbm\",\n",
    "    \"accuracy\": acc,\n",
    "    \"roc_auc\": roc_auc\n",
    "}]\n",
    "\n",
    "df_ref = pd.DataFrame(dict_ref)\n",
    "\n",
    "# save initial file\n",
    "df_ref.to_csv(\"model_metrics.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bfedbc",
   "metadata": {},
   "source": [
    "#### Save model to the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "49223726",
   "metadata": {},
   "outputs": [],
   "source": [
    "artifact_dir = tempfile.mkdtemp()\n",
    "\n",
    "# with SklearnModel there is support for pipelines\n",
    "sklearn_model = SklearnModel(estimator=clf, artifact_dir= artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c463a58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the env for runtime (don't need to upgrade ads... otherwise you would need a custom conda env)\n",
    "CONDA_ENV_SLUG = \"generalml_p37_cpu_v1\"\n",
    "\n",
    "sklearn_model.prepare(\n",
    "    inference_conda_env=CONDA_ENV_SLUG,\n",
    "    training_conda_env=CONDA_ENV_SLUG,\n",
    "    use_case_type=UseCaseType.BINARY_CLASSIFICATION,\n",
    "    as_onnx=False,\n",
    "    X_sample=X_test,\n",
    "    y_sample=y_test,\n",
    "    force_overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1f36f7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /tmp/tmpkwqfsp4x ...\n",
      "Model is successfully loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [1, 1, 0, 1, 0]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn_model.verify(X_test.head(5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "55218f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add info on reference dataset used for training\n",
    "\n",
    "ref_url = \"oci://drift_input@frqap2zhtzbe/reference.csv\"\n",
    "\n",
    "sklearn_model.metadata_custom.add(key='reference dataset', value=ref_url, category=MetadataCustomCategory.TRAINING_AND_VALIDATION_DATASETS, \n",
    "                                  description='Reference dataset url. From this dataset have been extracted train/validation dataset', replace=True)\n",
    "\n",
    "sklearn_model.metadata_custom.add(key='metrics on reference set', value=str(metrics), category=MetadataCustomCategory.PERFORMANCE, \n",
    "                                  description='Metrics evaluated on reference dataset', replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aa341d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data:\n",
       "- category: Training Environment\n",
       "  description: The URI of the training conda environment.\n",
       "  key: CondaEnvironmentPath\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/General Machine Learning\n",
       "    for CPUs on Python 3.7/1.0/generalml_p37_cpu_v1\n",
       "- category: Training Environment\n",
       "  description: The conda environment where the model was trained.\n",
       "  key: CondaEnvironment\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/General Machine Learning\n",
       "    for CPUs on Python 3.7/1.0/generalml_p37_cpu_v1\n",
       "- category: Training Profile\n",
       "  description: The model serialization format.\n",
       "  key: ModelSerializationFormat\n",
       "  value: joblib\n",
       "- category: Training Environment\n",
       "  description: The slug name of the training conda environment.\n",
       "  key: SlugName\n",
       "  value: generalml_p37_cpu_v1\n",
       "- category: Other\n",
       "  description: ''\n",
       "  key: ClientLibrary\n",
       "  value: ADS\n",
       "- category: Performance\n",
       "  description: Metrics evaluated on reference dataset\n",
       "  key: metrics on reference set\n",
       "  value: '{''accuracy'': 0.9494, ''roc_auc'': 0.9951}'\n",
       "- category: Training Environment\n",
       "  description: The conda environment type, can be published or datascience.\n",
       "  key: EnvironmentType\n",
       "  value: data_science\n",
       "- category: Training Environment\n",
       "  description: The list of files located in artifacts folder.\n",
       "  key: ModelArtifacts\n",
       "  value: score.py, model.joblib, runtime.yaml\n",
       "- category: Training and Validation Datasets\n",
       "  description: Reference dataset url. From this dataset have been extracted train/validation\n",
       "    dataset\n",
       "  key: reference dataset\n",
       "  value: oci://drift_input@frqap2zhtzbe/reference.csv"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all custom metadata\n",
    "sklearn_model.metadata_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eafdccc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /tmp/tmpkwqfsp4x ...\n",
      "Model is successfully loaded.\n",
      "['input_schema.json', 'score.py', 'model.joblib', 'runtime.yaml', 'output_schema.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact:/tmp/saved_model_3743bb7d-09ca-450e-96e7-301b7611395b.zip\n",
      "Model id in Model Catalog is ocid1.datasciencemodel.oc1.eu-frankfurt-1.amaaaaaangencdyasojemavtoshdggls4rg27i2qctcin6xz3yi3yevhnaha\n"
     ]
    }
   ],
   "source": [
    "# save to the Model Catalog\n",
    "\n",
    "MODEL_NAME = \"employee-attrition-lgbm05\"\n",
    "model_id = sklearn_model.save(display_name=MODEL_NAME)\n",
    "\n",
    "print(f\"Model id in Model Catalog is {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8878fe0",
   "metadata": {},
   "source": [
    "### Second Part: analysis on a new dataset\n",
    "\n",
    "see: Notebook part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067dced6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc38ecc2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mygeneralml_p37_cpu_v1_0]",
   "language": "python",
   "name": "conda-env-mygeneralml_p37_cpu_v1_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
