{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad7d43fe",
   "metadata": {},
   "source": [
    "### Demo: train the model and save to Model Catalog\n",
    "\n",
    "* In this Notebook we will see how to train a sklearn pipeline and save the model to the Model Catalog.\n",
    "* We will show how to add metadata (reference dataset, metrics..)\n",
    "* How to deploy the model as a REST service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f17deb42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import os\n",
    "import tempfile\n",
    "\n",
    "import ads\n",
    "from ads import set_auth\n",
    "\n",
    "# to save to Model Catalog\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_metadata import UseCaseType, MetadataCustomCategory\n",
    "from ads.model.framework.sklearn_model import SklearnModel\n",
    "\n",
    "# used to serialize the pipeline\n",
    "from pickle import dump, load\n",
    "\n",
    "import lightgbm as lgb\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import get_scorer, make_scorer, f1_score, roc_auc_score, accuracy_score, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# added to handle with pipelines\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ec10f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.6.2\n"
     ]
    }
   ],
   "source": [
    "# we need ads 2.5.10 or greater\n",
    "print(ads.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "353715c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:root:~/.oci/config file not exists, default value oci.config.DEFAULT_LOCATION used instead\n"
     ]
    }
   ],
   "source": [
    "# set RP\n",
    "set_auth(auth='resource_principal')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e09980",
   "metadata": {},
   "source": [
    "### First Part: train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d68b0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# definisco le funzioni che identificano le categorie di colonne\n",
    "#\n",
    "def cat_cols_selector(df, target_name):\n",
    "    # the input is the dataframe\n",
    "    \n",
    "    # cols with less than THR values are considered categoricals\n",
    "    THR = 10\n",
    "    \n",
    "    nunique = df.nunique()\n",
    "    types = df.dtypes\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if ((types[col] == 'object') or (nunique[col] < THR)):\n",
    "            # print(col)\n",
    "            if col != target_name:\n",
    "                col_list.append(col)\n",
    "    \n",
    "    return col_list\n",
    "\n",
    "def num_cols_selector(df, target_name):\n",
    "    THR = 10\n",
    "    \n",
    "    types = df.dtypes\n",
    "    nunique = df.nunique()\n",
    "    \n",
    "    col_list = []\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if (types[col] != 'object') and (nunique[col] >= THR): \n",
    "            # print(col)\n",
    "            if col != target_name:\n",
    "                col_list.append(col)\n",
    "    \n",
    "    return col_list\n",
    "\n",
    "def load_as_dataframe(path):\n",
    "    ds = DatasetFactory.open(path,\n",
    "                             target=\"Attrition\").set_positive_class('Yes')\n",
    "\n",
    "    ds_up = ds.up_sample()\n",
    "\n",
    "    # drop unneeded columns\n",
    "    cols_to_drop = ['Directs','name', 'Over18','WeeklyWorkedHours','EmployeeNumber']\n",
    "\n",
    "    ds_used = ds_up.drop(columns=cols_to_drop)\n",
    "    \n",
    "    df_used = ds_used.to_pandas_dataframe()\n",
    "    \n",
    "    \n",
    "\n",
    "    # train, test split (lo faccio direttamente sui dataframe)\n",
    "    df_train, df_test = train_test_split(df_used, shuffle=True, test_size=0.2, random_state = 1234)\n",
    "\n",
    "    print(\"# of samples in train set\", df_train.shape[0])\n",
    "    print(\"# of samples in test set\", df_test.shape[0])\n",
    "    \n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8589a721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1f1277eda70447f921391b27221c093",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of samples in train set 1972\n",
      "# of samples in test set 494\n",
      "\n",
      "Numerical columns: ['Age', 'SalaryLevel', 'CommuteLength', 'HourlyRate', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked', 'PercentSalaryHike', 'YearsinIndustry', 'YearsOnJob', 'YearsAtCurrentLevel', 'YearsSinceLastPromotion', 'YearsWithCurrManager'] (13)\n",
      "\n",
      "Categorical columns: ['TravelForWork', 'JobFunction', 'EducationalLevel', 'EducationField', 'EnvironmentSatisfaction', 'Gender', 'JobInvolvement', 'JobLevel', 'JobRole', 'JobSatisfaction', 'MaritalStatus', 'OverTime', 'PerformanceRating', 'RelationshipSatisfaction', 'StockOptionLevel', 'TrainingTimesLastYear', 'WorkLifeBalance'] (17)\n"
     ]
    }
   ],
   "source": [
    "# load the dataset and do upsampling\n",
    "TARGET = 'Attrition'\n",
    "\n",
    "attrition_path = \"/opt/notebooks/ads-examples/oracle_data/orcl_attrition.csv\"\n",
    "\n",
    "# ritorna un dataset su cui Ã¨ stato fatto l'upsampling\n",
    "df_train, df_test = load_as_dataframe(attrition_path)\n",
    "\n",
    "cat_cols = cat_cols_selector(df_train, TARGET)\n",
    "num_cols = num_cols_selector(df_train, TARGET)\n",
    "\n",
    "print()\n",
    "print(f'Numerical columns: {num_cols} ({len(num_cols)})')\n",
    "print()\n",
    "print(f'Categorical columns: {cat_cols} ({len(cat_cols)})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dcfbc576",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# creo la parte Transformers per le pipeline\n",
    "#\n",
    "\n",
    "# per questo dataset non vi sono missing values\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(missing_values=np.nan, strategy='mean')),\n",
    "    ('standard_scaler', StandardScaler())])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ordinal_encoder', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "\n",
    "transformations = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_transformer, num_cols),\n",
    "        ('cat', categorical_transformer, cat_cols)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c4c14da",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train = df_train.drop([TARGET], axis=1), df_train[TARGET]\n",
    "X_test, y_test = df_test.drop([TARGET], axis=1), df_test[TARGET]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8a3626c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 5, 6, 7, 8, 10, 11, 12, 13, 14, 18, 20, 21, 22, 24, 25]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prepare cat_cols for lightgbm\n",
    "cat_cols_index = [i for i, x in enumerate(X_train.columns) if x in cat_cols]\n",
    "\n",
    "cat_cols_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f75aafa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# definisco la pipeline completa\n",
    "#\n",
    "params = {\n",
    "    # info\n",
    "    \"verbose\" : 1,\n",
    "    \"categorical_feature\": cat_cols_index\n",
    "}\n",
    "\n",
    "pipe = Pipeline(steps=[('preprocessor', transformations),\n",
    "                           ('clf', lgb.LGBMClassifier(**params))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d3fd06b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Warning] Met negative value in categorical features, will convert it to NaN\n",
      "[LightGBM] [Info] Number of positive: 994, number of negative: 978\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.087244 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 478\n",
      "[LightGBM] [Info] Number of data points in the train set: 1972, number of used features: 30\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.504057 -> initscore=0.016228\n",
      "[LightGBM] [Info] Start training from score 0.016228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('preprocessor',\n",
       "                 ColumnTransformer(transformers=[('num',\n",
       "                                                  Pipeline(steps=[('imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('standard_scaler',\n",
       "                                                                   StandardScaler())]),\n",
       "                                                  ['Age', 'SalaryLevel',\n",
       "                                                   'CommuteLength',\n",
       "                                                   'HourlyRate',\n",
       "                                                   'MonthlyIncome',\n",
       "                                                   'MonthlyRate',\n",
       "                                                   'NumCompaniesWorked',\n",
       "                                                   'PercentSalaryHike',\n",
       "                                                   'YearsinIndustry',\n",
       "                                                   'YearsOnJob',\n",
       "                                                   'YearsAtCurrentLevel',\n",
       "                                                   'YearsSinceLastPromoti...\n",
       "                                                   'EducationField',\n",
       "                                                   'EnvironmentSatisfaction',\n",
       "                                                   'Gender', 'JobInvolvement',\n",
       "                                                   'JobLevel', 'JobRole',\n",
       "                                                   'JobSatisfaction',\n",
       "                                                   'MaritalStatus', 'OverTime',\n",
       "                                                   'PerformanceRating',\n",
       "                                                   'RelationshipSatisfaction',\n",
       "                                                   'StockOptionLevel',\n",
       "                                                   'TrainingTimesLastYear',\n",
       "                                                   'WorkLifeBalance'])])),\n",
       "                ('clf',\n",
       "                 LGBMClassifier(categorical_feature=[1, 3, 5, 6, 7, 8, 10, 11,\n",
       "                                                     12, 13, 14, 18, 20, 21, 22,\n",
       "                                                     24, 25],\n",
       "                                verbose=1))])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e54a013",
   "metadata": {},
   "source": [
    "### Score the Model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9bb598d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation set result:\n",
      "{'accuracy': 0.9534, 'roc_auc': 0.9944}\n"
     ]
    }
   ],
   "source": [
    "# better with categorical features\n",
    "\n",
    "test_pred = pipe.predict(X_test)\n",
    "test_probas = pipe.predict_proba(X_test)\n",
    "\n",
    "print('Validation set result:')\n",
    "\n",
    "roc_auc = round(roc_auc_score(y_test, test_probas[:,1]), 4)\n",
    "acc = round(accuracy_score(y_test, test_pred), 4)\n",
    "\n",
    "# this is the Object that will be saved in the Model Catalog\n",
    "metrics = {\n",
    "    \"accuracy\" : acc,\n",
    "    \"roc_auc\" : roc_auc\n",
    "}\n",
    "\n",
    "print(str(metrics))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d281c9a",
   "metadata": {},
   "source": [
    "#### Save metrics and model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5a352c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save in a file the metrics computed on the reference set\n",
    "now = datetime.now().strftime('%Y-%m-%d %H:%M')\n",
    "\n",
    "dict_ref = [{\n",
    "    \"ts_date\": now,\n",
    "    \"model_name\": \"lgb1\",\n",
    "    \"algorithm\": \"lightgbm\",\n",
    "    \"accuracy\": acc,\n",
    "    \"roc_auc\": roc_auc\n",
    "}]\n",
    "\n",
    "df_ref = pd.DataFrame(dict_ref)\n",
    "\n",
    "# save initial file\n",
    "df_ref.to_csv(\"model_metrics.csv\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48199019",
   "metadata": {},
   "source": [
    "#### Save model to the Model Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "94f3400c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifact_dir = tempfile.mkdtemp()\n",
    "artifact_dir = \"model_dir\"\n",
    "\n",
    "# with SklearnModel there is support for pipelines\n",
    "sklearn_model = SklearnModel(estimator=pipe, artifact_dir= artifact_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b063de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the env for runtime (don't need to upgrade ads... otherwise you would need a custom conda env)\n",
    "CONDA_ENV_SLUG = \"generalml_p37_cpu_v1\"\n",
    "\n",
    "sklearn_model.prepare(\n",
    "    inference_conda_env=CONDA_ENV_SLUG,\n",
    "    training_conda_env=CONDA_ENV_SLUG,\n",
    "    use_case_type=UseCaseType.BINARY_CLASSIFICATION,\n",
    "    as_onnx=False,\n",
    "    X_sample=X_test,\n",
    "    y_sample=y_test,\n",
    "    force_overwrite=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "774a2fcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /home/datascience/data-drift-analysis/model_dir ...\n",
      "Model is successfully loaded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'prediction': [1, 1, 0, 1, 0, 1, 1, 1, 0, 0]}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "sklearn_model.verify(X_test.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6947ee45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 0, 1, 0, 1, 1, 1, 0, 0])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compare with expected values\n",
    "y_test[:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e01611f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add info on reference dataset used for training and on metrics in validation\n",
    "\n",
    "ref_url = \"oci://drift_input@frqap2zhtzbe/reference.csv\"\n",
    "\n",
    "sklearn_model.metadata_custom.add(key='reference dataset', value=ref_url, category=MetadataCustomCategory.TRAINING_AND_VALIDATION_DATASETS, \n",
    "                                  description='Reference dataset url. From this dataset have been extracted train/validation dataset', replace=True)\n",
    "\n",
    "sklearn_model.metadata_custom.add(key='metrics on reference set', value=str(metrics), category=MetadataCustomCategory.PERFORMANCE, \n",
    "                                  description='Metrics evaluated on reference dataset', replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0530bb9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "data:\n",
       "- category: Training Environment\n",
       "  description: The conda environment type, can be published or datascience.\n",
       "  key: EnvironmentType\n",
       "  value: data_science\n",
       "- category: Training Environment\n",
       "  description: The conda environment where the model was trained.\n",
       "  key: CondaEnvironment\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/General_Machine_Learning_for_CPUs_on_Python_3.7/1.0/generalml_p37_cpu_v1\n",
       "- category: Other\n",
       "  description: ''\n",
       "  key: ClientLibrary\n",
       "  value: ADS\n",
       "- category: Performance\n",
       "  description: Metrics evaluated on reference dataset\n",
       "  key: metrics on reference set\n",
       "  value: '{''accuracy'': 0.9534, ''roc_auc'': 0.9944}'\n",
       "- category: Training Environment\n",
       "  description: The URI of the training conda environment.\n",
       "  key: CondaEnvironmentPath\n",
       "  value: oci://service-conda-packs@id19sfcrra6z/service_pack/cpu/General_Machine_Learning_for_CPUs_on_Python_3.7/1.0/generalml_p37_cpu_v1\n",
       "- category: Training and Validation Datasets\n",
       "  description: Reference dataset url. From this dataset have been extracted train/validation\n",
       "    dataset\n",
       "  key: reference dataset\n",
       "  value: oci://drift_input@frqap2zhtzbe/reference.csv\n",
       "- category: Training Profile\n",
       "  description: The model serialization format.\n",
       "  key: ModelSerializationFormat\n",
       "  value: joblib\n",
       "- category: Training Environment\n",
       "  description: The list of files located in artifacts folder.\n",
       "  key: ModelArtifacts\n",
       "  value: model.joblib, score.py, runtime.yaml\n",
       "- category: Training Environment\n",
       "  description: The slug name of the training conda environment.\n",
       "  key: SlugName\n",
       "  value: generalml_p37_cpu_v1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check all custom metadata\n",
    "sklearn_model.metadata_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aa883b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading model.joblib from model directory /home/datascience/data-drift-analysis/model_dir ...\n",
      "Model is successfully loaded.\n",
      "['model.joblib', 'score.py', 'output_schema.json', 'runtime.yaml', 'input_schema.json']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "loop1:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artifact:/tmp/saved_model_62d64a38-e596-42f9-ae03-49d401c04e13.zip\n",
      "Model id in Model Catalog is ocid1.datasciencemodel.oc1.us-sanjose-1.amaaaaaangencdya2gd5hfcloafnmhalfuvzklzuutzcrromwzurcxa7qvha\n"
     ]
    }
   ],
   "source": [
    "# save to the Model Catalog\n",
    "\n",
    "MODEL_NAME = \"employee-attrition-lgbm01\"\n",
    "model_id = sklearn_model.save(display_name=MODEL_NAME)\n",
    "\n",
    "print(f\"Model id in Model Catalog is {model_id}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daabd611",
   "metadata": {},
   "source": [
    "### Deploy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a43ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f1b594a",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_GROUP_OCID = \"ocid1.loggroup.oc1.us-sanjose-1.amaaaaaangencdya6t66jzxuvjrtnyr344rbaez5ms4ejjhjtr6ji5uudizq\"\n",
    "ACCESS_LOG_OCID = \"ocid1.log.oc1.us-sanjose-1.amaaaaaangencdya37hw4ol4kldg3hgn2xgd2hq357cvroait37in2dh7rna\"\n",
    "PREDICT_LOG_OCID = \"ocid1.log.oc1.us-sanjose-1.amaaaaaangencdyaqjy6nsyn6qw7brgohpyutb6zlazkwbnolow3frlbta2a\"\n",
    "\n",
    "sklearn_model.deploy(deployment_instance_shape=\"VM.Standard2.4\",\n",
    "                    display_name=\"lightgbm01-deploy2\",\n",
    "                    deployment_instance_count=1,\n",
    "                    deployment_log_group_id=LOG_GROUP_OCID,\n",
    "                    deployment_predict_log_id=PREDICT_LOG_OCID,\n",
    "                    deployment_access_log_id=ACCESS_LOG_OCID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6cffd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn_model.summary_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43c2fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mygeneralml_p37_cpu_v1_0]",
   "language": "python",
   "name": "conda-env-mygeneralml_p37_cpu_v1_0-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
